dataset:
  is_split_by_sentences: true
  datasets:
    - "tomekkorbak/detoxify-pile-chunk3-0-50000"
    - "tomekkorbak/detoxify-pile-chunk3-50000-100000"
    - "tomekkorbak/detoxify-pile-chunk3-100000-150000"
    - "tomekkorbak/detoxify-pile-chunk3-150000-200000"
    - "tomekkorbak/detoxify-pile-chunk3-200000-250000"
    - "tomekkorbak/detoxify-pile-chunk3-250000-300000"
    - "tomekkorbak/detoxify-pile-chunk3-300000-350000"
    - "tomekkorbak/detoxify-pile-chunk3-350000-400000"
    - "tomekkorbak/detoxify-pile-chunk3-400000-450000"
    - "tomekkorbak/detoxify-pile-chunk3-450000-500000"
    - "tomekkorbak/detoxify-pile-chunk3-500000-550000"
    - "tomekkorbak/detoxify-pile-chunk3-550000-600000"
    - "tomekkorbak/detoxify-pile-chunk3-600000-650000"
    - "tomekkorbak/detoxify-pile-chunk3-650000-700000"
    - "tomekkorbak/detoxify-pile-chunk3-700000-750000"
    - "tomekkorbak/detoxify-pile-chunk3-750000-800000"
    - "tomekkorbak/detoxify-pile-chunk3-800000-850000"
    - "tomekkorbak/detoxify-pile-chunk3-850000-900000"
    - "tomekkorbak/detoxify-pile-chunk3-900000-950000"
    - "tomekkorbak/detoxify-pile-chunk3-950000-1000000"
    - "tomekkorbak/detoxify-pile-chunk3-1000000-1050000"
    - "tomekkorbak/detoxify-pile-chunk3-1050000-1100000"
    - "tomekkorbak/detoxify-pile-chunk3-1100000-1150000"
    - "tomekkorbak/detoxify-pile-chunk3-1150000-1200000"
    - "tomekkorbak/detoxify-pile-chunk3-1200000-1250000"
    - "tomekkorbak/detoxify-pile-chunk3-1250000-1300000"
    - "tomekkorbak/detoxify-pile-chunk3-1300000-1350000"
    - "tomekkorbak/detoxify-pile-chunk3-1350000-1400000"
    - "tomekkorbak/detoxify-pile-chunk3-1400000-1450000"
    - "tomekkorbak/detoxify-pile-chunk3-1450000-1500000"
    - "tomekkorbak/detoxify-pile-chunk3-1500000-1550000"
    - "tomekkorbak/detoxify-pile-chunk3-1550000-1600000"
    - "tomekkorbak/detoxify-pile-chunk3-1600000-1650000"
    - "tomekkorbak/detoxify-pile-chunk3-1650000-1700000"
    - "tomekkorbak/detoxify-pile-chunk3-1700000-1750000"
    - "tomekkorbak/detoxify-pile-chunk3-1750000-1800000"
    - "tomekkorbak/detoxify-pile-chunk3-1800000-1850000"
    - "tomekkorbak/detoxify-pile-chunk3-1850000-1900000"
    - "tomekkorbak/detoxify-pile-chunk3-1900000-1950000"


tokenizer:
  path_or_name: gpt2

model:
  path_or_name: gpt2
  from_scratch: true
  gpt2_config_kwargs:
      reorder_and_upcast_attn: true
      scale_attn_by: true

objective:
  name: MLE

training:
  output_dir: training_output104340
  effective_batch_size: 64
  num_tokens: 3.3E+9
  learning_rate: 0.0005
  per_device_train_batch_size: 8
  fp16: true
  weight_decay: 0.1
  evaluation_strategy: 'no'
  logging_steps: 1
  warmup_ratio: 0.01
  logging_first_step: true
  seed: 42
  remove_unused_columns: false
  dataloader_num_workers: 0
  save_strategy: steps
  save_steps: 25354

generation:
  force_call_on: [25354]
  scorer_config:
    class_name: DetoxifyToxicityScorer
    device: "cuda:0"
  metrics_configs:
    - class_name: Length
    - class_name: NGramStats
      n: 1
    - class_name: NGramStats
      n: 2
    - class_name: SelfBlEU
      n: 5
  scenario_configs:
    - name: unconditional
      num_samples: 4096
      generate_kwargs:
        do_sample: true
        max_length: 128
        min_length: 10
        temperature: 0.7
        top_p: 0.9
        top_k: 0

kl_gpt3_callback:
  num_samples: 4096
  max_tokens: 64
  force_call_on: [25354]
  gpt3_kwargs:
    model_name: davinci
